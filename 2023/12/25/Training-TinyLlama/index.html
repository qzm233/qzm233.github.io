<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Training TinyLlama to clinic domain. | Hello,World. This is Zimo.</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Introduction of LLMsLLMs, or Large Language Models, are advanced AI systems trained on vast amounts of text data. They leverage deep learning techniques, particularly the Transformer architecture, to">
<meta property="og:type" content="article">
<meta property="og:title" content="Training TinyLlama to clinic domain.">
<meta property="og:url" content="http://qzm233.github.io/2023/12/25/Training-TinyLlama/index.html">
<meta property="og:site_name" content="Hello,World. This is Zimo.">
<meta property="og:description" content="Introduction of LLMsLLMs, or Large Language Models, are advanced AI systems trained on vast amounts of text data. They leverage deep learning techniques, particularly the Transformer architecture, to">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-12-25T07:19:48.000Z">
<meta property="article:modified_time" content="2023-12-25T10:00:04.674Z">
<meta property="article:author" content="Zimo">
<meta property="article:tag" content="clinic">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hello,World. This is Zimo." type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hello,World. This is Zimo.</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://qzm233.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Training-TinyLlama" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/12/25/Training-TinyLlama/" class="article-date">
  <time class="dt-published" datetime="2023-12-25T07:19:48.000Z" itemprop="datePublished">2023-12-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Training TinyLlama to clinic domain.
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Introduction-of-LLMs"><a href="#Introduction-of-LLMs" class="headerlink" title="Introduction of LLMs"></a>Introduction of LLMs</h2><p>LLMs, or Large Language Models, are advanced AI systems trained on vast amounts of text data. They leverage deep learning techniques, particularly the Transformer architecture, to learn patterns and structures in language. LLMs are capable of generating coherent text, understanding context, and performing complex language tasks such as translation, summarization, and question-answering.</p>
<h2 id="The-Importance-of-LLMs-in-Specific-Domains"><a href="#The-Importance-of-LLMs-in-Specific-Domains" class="headerlink" title="The Importance of LLMs in Specific Domains"></a>The Importance of LLMs in Specific Domains</h2><p>In specialized fields like clinical practice, law, and finance, the accuracy and expertise of information are paramount. The application of LLMs can enhance work efficiency and quality in these domains while minimizing human errors. For instance, in clinical settings, LLMs can assist doctors in quickly accessing medical records and literature to aid in diagnosis; in legal practice, they can help lawyers with case research and drafting legal documents; in finance, LLMs can provide market analysis and risk assessments.</p>
<h2 id="Fine-Tuning-LLMs-for-Specific-Domains"><a href="#Fine-Tuning-LLMs-for-Specific-Domains" class="headerlink" title="Fine-Tuning LLMs for Specific Domains"></a>Fine-Tuning LLMs for Specific Domains</h2><p>To make LLMs more effective in specific domains, they need to be fine-tuned. Fine-tuning involves training the model on a dataset specific to the target domain, adjusting the model’s parameters to adapt to the new context. The fine-tuning process typically includes the following steps:</p>
<ol>
<li><strong>Data Collection</strong>: Gather a large corpus of text data relevant to the target domain.</li>
<li><strong>Data Preprocessing</strong>: Clean and format the data to ensure it’s suitable for model training.</li>
<li><strong>Fine-Tuning Training</strong>: Train the model on the preprocessed dataset, adjusting parameters to adapt to the new domain.</li>
<li><strong>Evaluation and Iteration</strong>: Evaluate the model’s performance in the new domain and iterate as necessary for optimization.</li>
</ol>
<h2 id="Potential-Directions-for-Applying-LLMs"><a href="#Potential-Directions-for-Applying-LLMs" class="headerlink" title="Potential Directions for Applying LLMs"></a>Potential Directions for Applying LLMs</h2><ol>
<li><strong>Clinical Diagnostic Assistance</strong>: LLMs can analyze medical records to help doctors identify disease patterns and provide diagnostic suggestions.</li>
<li><strong>Legal Document Automation</strong>: Automatically generate contracts, legal documents, and legal opinions to reduce the workload of lawyers.</li>
<li><strong>Financial Risk Assessment</strong>: Analyze financial data to predict market trends and support investment decisions.</li>
<li><strong>Automated Customer Service</strong>: Provide natural language processing capabilities in customer service to improve response times and customer satisfaction.</li>
<li><strong>Regulatory Compliance</strong>: Assist in ensuring that businesses comply with regulatory requirements by analyzing and flagging potential non-compliance issues.</li>
<li><strong>Research and Development</strong>: In scientific research, LLMs can help identify relevant literature, summarize findings, and even suggest new research directions based on existing knowledge.</li>
<li><strong>Personalized Recommendations</strong>: In various industries, LLMs can tailor recommendations to individual needs, preferences, or circumstances, enhancing user experiences.</li>
</ol>
<h2 id="My-trail-of-Finetuning-TinyLLaMA-1b-with-clinical-instruction-data-with-QLoRA-method"><a href="#My-trail-of-Finetuning-TinyLLaMA-1b-with-clinical-instruction-data-with-QLoRA-method" class="headerlink" title="My trail of Finetuning TinyLLaMA-1b with clinical instruction data with QLoRA method."></a>My trail of Finetuning TinyLLaMA-1b with clinical instruction data with QLoRA method.</h2><ol>
<li><strong>Model</strong> <a target="_blank" rel="noopener" href="https://modelscope.cn/models/chaoscodes/TinyLlama-1.1B-Chat-v0.1">TinyLLaMA-1b</a></li>
<li><strong>Data</strong> <a target="_blank" rel="noopener" href="https://github.com/Kent0n-Li/ChatDoctor">clinical instruction data</a></li>
<li><strong>QLoRa Finetuning</strong> One can check the github code to find the method of fine-tuning with <a target="_blank" rel="noopener" href="https://github.com/artidoro/qlora">QLoRa</a>. Due to some constrains, only one epoch is conducted. QLoRa truely promote the training speed. There are some blogs that one can refer to.<a target="_blank" rel="noopener" href="https://blog.ovhcloud.com/fine-tuning-llama-2-models-using-a-single-gpu-qlora-and-ai-notebooks/">Blog by Mathieu Busquet</a> and [blog by ]</li>
<li><strong>Validation on MedMCQA dataset</strong> <a target="_blank" rel="noopener" href="https://github.com/medmcqa/medmcqa">MedMCQA</a> is designed to address realworld medical entrance exam questions. After one epoch finetuning, LLM always talks foolishly. Because of finetuning dataset, the model is always act like a Robot but not an Examnee. One should add the proper prompt to get an answer of option and the accuracy is about 20%. One can refer to the <a target="_blank" rel="noopener" href="https://saankhya.medium.com/mistral-instruct-7b-finetuning-on-medmcqa-dataset-6ec2532b1ff1">blog by Saankhya Mondal</a>.</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://qzm233.github.io/2023/12/25/Training-TinyLlama/" data-id="clqklhmvz00003gbsandl8vtp" data-title="Training TinyLlama to clinic domain." class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/clinic/" rel="tag">clinic</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2023/12/14/My-First/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">My First</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/clinic/" rel="tag">clinic</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/finance/" rel="tag">finance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/law/" rel="tag">law</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/LLM/" style="font-size: 20px;">LLM</a> <a href="/tags/clinic/" style="font-size: 20px;">clinic</a> <a href="/tags/finance/" style="font-size: 10px;">finance</a> <a href="/tags/law/" style="font-size: 10px;">law</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/12/25/Training-TinyLlama/">Training TinyLlama to clinic domain.</a>
          </li>
        
          <li>
            <a href="/2023/12/14/My-First/">My First</a>
          </li>
        
          <li>
            <a href="/2023/12/14/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 Zimo<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>
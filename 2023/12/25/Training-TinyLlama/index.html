<!DOCTYPE html>
<html lang="en">
    
    <style>
        body
        {
            font-family: "Times New Roman", Helvetica, Tahoma, Arial,   LXGW WenKai   "notoserifsc-medium", "Microsoft YaHei", "Hiragino Sans GB", "WenQuanYi Micro Hei", sans-serif !important;

        }
    </style>

    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
    <meta name="description" content="Training TinyLlama to clinic domain." />
    <meta name="hexo-theme-A4" content="v1.8.8" />
    <link rel="alternate icon" type="image/webp" href="/img/favicon.webp">
    <title>Zimo.</title>

    
        
<link rel="stylesheet" href="/css/highlight/style1.css">

        
<link rel="stylesheet" href="/css/reset.css">

        
<link rel="stylesheet" href="/css/markdown.css">

        
<link rel="stylesheet" href="/css/fonts.css">
 
         <!--Ê≥®ÊÑèÔºöÈ¶ñÈ°µÊó¢‰∏çÊòØpost‰πü‰∏çÊòØpage-->
        
        
        
<link rel="stylesheet" href="/css/ui.css">
 
        
<link rel="stylesheet" href="/css/style.css">


        
            <!--ËøîÂõûÈ°∂ÈÉ®css-->
            
<link rel="stylesheet" href="/css/returnToTop.css">

            
<link rel="stylesheet" href="/css/unicons.css">

        
        
            <!--ÁõÆÂΩï-->
            
<link rel="stylesheet" href="/css/toc.css">

        
    

    
        
<link rel="stylesheet" href="/css/returnToLastPage.css">

    
    
   
<link rel="stylesheet" href="/css/lightgallery.min.css">


<meta name="generator" content="Hexo 7.0.0"></head>
    
    <style>
        :root {
            --waline-theme-color: #9e5345; 
            --waline-color: #9e5345; 
            --waline-border-color: #9e5345; 
            --waline-white: #9e5345; 
            --waline-bgcolor-light: #efeae2;  
        }
        body {
            color: #9e5345;
            background: #e8e0c9;
        }
        .post-md code {
            background: #e8e0c9;
            color: #2e5041; 
        }
        .post-md pre, .post-md .highlight {
            background: #e8e0c9;
            color: #2e5041; 
        }
        pre .string, pre .value, pre .inheritance, pre .header, pre .ruby .symbol, pre .xml .cdata {
            color: #9e5345;
        }
        pre .number, pre .preprocessor, pre .built_in, pre .literal, pre .params, pre .constant {
            color: #9e5345;
        }
        .year-font-color {
            color: #9e5345 !important;
        }
        .wl-card span.wl-nick {
            color: #9e5345; 
        }
        .wl-card .wl-badge {
            border: 1px solid #9e5345;
            color: #9e5345; 
        }
        .wl-btn {
            border: 1px solid #9e5345; 
            color:  #9e5345;  
        }
        .wl-btn.primary {
            color: #efeae2; 
        }
        .wl-header label {
            color: #9e5345;
        }
        a {
            color: #2e5041;
        }

        .post-md a {
            color: #2e5041;
        }

        .nav li a {
            color: #2e5041;
        }

        .archive-main a:link {
            color: #2e5041;
        }
        .archive-main a:visited {
            color: #9c9caf; 
        }

        .archive li span {
            color: #9e5345;
        }

        .post-main-title {
            color: #9e5345;
        }

        .post-md h1,
        .post-md h2,
        .post-md h3,
        .post-md h4,
        .post-md h5,
        .post-md h6 {
            color: #9e5345;
        }

        [data-waline] p {
            color: #9e5345;
        }
        [data-waline] a {
            color: #9e5345;
        } 
        .wl-sort li.active {
            color: #9e5345;
        }

        .wl-card .wl-meta>span {
            background: #efeae2;
        }

        .paper {
            background: #e8e0c9;
        }

        .index-main {
            background: #efeae2;
        }

        .paper-main {
            background: #efeae2;
        }

        .wl-panel {
            background: #efeae2;
        }

        .archive li:nth-child(odd) {
            background: #efeae2;
            ;
        }

        .archive li:nth-child(even) {
            background: #efeae2;
        }

        .post-md table tr:nth-child(odd) td {
            background: #efeae2;
        }

        .post-md table tr:nth-child(even) td {
            background: #efeae2;
        }

    
        .progress-wrap::after {
            color: #9e5345; /* ÁÆ≠Â§¥ÁöÑÈ¢úËâ≤ */
        }
        .progress-wrap svg.progress-circle path {
	        stroke: #9e5345; /* ËæπÊ°ÜÁöÑÈ¢úËâ≤ */
        }
        .progress-wrap::before {
	        background-image: linear-gradient(298deg, #2e5041, #2e5041); /* Èº†Ê†áÊªëËøáÁöÑÁÆ≠Â§¥È¢úËâ≤ */
         }

        .return-to-last-progress-wrap::after {
            color: #9e5345; /* ÁÆ≠Â§¥ÁöÑÈ¢úËâ≤ */
        }
        .return-to-last-progress-wrap svg.progress-circle path {
	        stroke: #9e5345; /* ËæπÊ°ÜÁöÑÈ¢úËâ≤ */
        }
        .return-to-last-progress-wrap::before {
	        background-image: linear-gradient(298deg, #2e5041, #2e5041); /* Èº†Ê†áÊªëËøáÁöÑÁÆ≠Â§¥È¢úËâ≤ */
         }

         .left-toc-container::-webkit-scrollbar-thumb {
            background-color: #9e5345; /* ËÆæÁΩÆÊªöÂä®Êù°ÊãñÂä®ÂùóÁöÑÈ¢úËâ≤ */
        }

        .bs-docs-sidebar .nav>.active>a,
        .bs-docs-sidebar .nav>li>a:hover,
        .bs-docs-sidebar .nav>li>a:focus {
            color: #2e5041;
            border-left-color: #2e5041;
        }
        .bs-docs-sidebar .nav>li>a {
            color:  #9e5345;
        }
    </style>

    
    <body>
        
            <div class="left-toc-container">
                <nav id="toc" class="bs-docs-sidebar"></nav>
            </div>
        
        <div class="paper">
            
            
            
            
                <div class="shadow-drop-2-bottom paper-main">
                    


<div class="header">
    <div class="header-container">
        <img style="
        width: 56px;
        height: auto;" alt="^-^" cache-control="max-age=86400" class="header-img" src="/img/favicon.webp" width="10%"></img>
        <div class="header-content">
            <a class="logo" href="/">Zimo.</a> 
            <span class="description"></span> 
        </div>
        
    </div>
    
   
    <ul class="nav">
        
            
                <li><a href="/">Home</a></li>
            
        
            
                <li><a href="/list/">Articles</a></li>
            
        
            
                <li><a href="/about/">About</a></li>
            
        
            
                <li><a href="/moment/">Moment Thought</a></li>
            
        
    </ul>
</div> 
        
                    
                    

                    
                    
                    
                    <!--ËØ¥ÊòéÊòØÊñáÁ´†postÈ°µÈù¢-->
                    
                        <div class="post-main">

    
        <div class="post-main-title">
            Training TinyLlama to clinic domain.
        </div>
      
    

    <div class="post-md">
        
            
                <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#introduction-of-llms"><span class="post-toc-text">Introduction of LLMs</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#the-importance-of-llms-in-specific-domains"><span class="post-toc-text">The Importance of
LLMs in Specific Domains</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#fine-tuning-llms-for-specific-domains"><span class="post-toc-text">Fine-Tuning LLMs for
Specific Domains</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#potential-directions-for-applying-llms"><span class="post-toc-text">Potential Directions for
Applying LLMs</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#my-trail-of-finetuning-tinyllama-1b-with-clinical-instruction-data-with-qlora-method."><span class="post-toc-text">My
trail of Finetuning TinyLLaMA-1b with clinical instruction data with
QLoRA method.</span></a></li></ol>
            
        
        <link rel="stylesheet" type="text/css" href="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="introduction-of-llms">Introduction of LLMs</h2>
<p>LLMs, or Large Language Models, are advanced AI systems trained on
vast amounts of text data. They leverage deep learning techniques,
particularly the Transformer architecture, to learn patterns and
structures in language. LLMs are capable of generating coherent text,
understanding context, and performing complex language tasks such as
translation, summarization, and question-answering.</p>
<h2 id="the-importance-of-llms-in-specific-domains">The Importance of
LLMs in Specific Domains</h2>
<p>In specialized fields like clinical practice, law, and finance, the
accuracy and expertise of information are paramount. The application of
LLMs can enhance work efficiency and quality in these domains while
minimizing human errors. For instance, in clinical settings, LLMs can
assist doctors in quickly accessing medical records and literature to
aid in diagnosis; in legal practice, they can help lawyers with case
research and drafting legal documents; in finance, LLMs can provide
market analysis and risk assessments.</p>
<h2 id="fine-tuning-llms-for-specific-domains">Fine-Tuning LLMs for
Specific Domains</h2>
<p>To make LLMs more effective in specific domains, they need to be
fine-tuned. Fine-tuning involves training the model on a dataset
specific to the target domain, adjusting the model's parameters to adapt
to the new context. The fine-tuning process typically includes the
following steps:</p>
<ol type="1">
<li><strong>Data Collection</strong>: Gather a large corpus of text data
relevant to the target domain.</li>
<li><strong>Data Preprocessing</strong>: Clean and format the data to
ensure it's suitable for model training.</li>
<li><strong>Fine-Tuning Training</strong>: Train the model on the
preprocessed dataset, adjusting parameters to adapt to the new
domain.</li>
<li><strong>Evaluation and Iteration</strong>: Evaluate the model's
performance in the new domain and iterate as necessary for
optimization.</li>
</ol>
<h2 id="potential-directions-for-applying-llms">Potential Directions for
Applying LLMs</h2>
<ol type="1">
<li><strong>Clinical Diagnostic Assistance</strong>: LLMs can analyze
medical records to help doctors identify disease patterns and provide
diagnostic suggestions.</li>
<li><strong>Legal Document Automation</strong>: Automatically generate
contracts, legal documents, and legal opinions to reduce the workload of
lawyers.</li>
<li><strong>Financial Risk Assessment</strong>: Analyze financial data
to predict market trends and support investment decisions.</li>
<li><strong>Automated Customer Service</strong>: Provide natural
language processing capabilities in customer service to improve response
times and customer satisfaction.</li>
<li><strong>Regulatory Compliance</strong>: Assist in ensuring that
businesses comply with regulatory requirements by analyzing and flagging
potential non-compliance issues.</li>
<li><strong>Research and Development</strong>: In scientific research,
LLMs can help identify relevant literature, summarize findings, and even
suggest new research directions based on existing knowledge.</li>
<li><strong>Personalized Recommendations</strong>: In various
industries, LLMs can tailor recommendations to individual needs,
preferences, or circumstances, enhancing user experiences.</li>
</ol>
<h2
id="my-trail-of-finetuning-tinyllama-1b-with-clinical-instruction-data-with-qlora-method.">My
trail of Finetuning TinyLLaMA-1b with clinical instruction data with
QLoRA method.</h2>
<ol type="1">
<li><strong>Model</strong> <a
target="_blank" rel="noopener" href="https://modelscope.cn/models/chaoscodes/TinyLlama-1.1B-Chat-v0.1">TinyLLaMA-1b</a></li>
<li><strong>Data</strong> <a
target="_blank" rel="noopener" href="https://github.com/Kent0n-Li/ChatDoctor">clinical instruction
data</a></li>
<li><strong>QLoRa Finetuning</strong> One can check the github code to
find the method of fine-tuning with <a
target="_blank" rel="noopener" href="https://github.com/artidoro/qlora">QLoRa</a>. Due to some
constrains, only one epoch is conducted. QLoRa truely promote the
training speed. There are some blogs that one can refer to.<a
target="_blank" rel="noopener" href="https://blog.ovhcloud.com/fine-tuning-llama-2-models-using-a-single-gpu-qlora-and-ai-notebooks/">Blog
by Mathieu Busquet</a> and [blog by ]</li>
<li><strong>Validation on MedMCQA dataset</strong> <a
target="_blank" rel="noopener" href="https://github.com/medmcqa/medmcqa">MedMCQA</a> is designed to
address realworld medical entrance exam questions. After one epoch
finetuning, LLM always talks foolishly. Because of finetuning dataset,
the model is always act like a Robot but not an Examnee. One should add
the proper prompt to get an answer of option and the accuracy is about
20%. One can refer to the <a
target="_blank" rel="noopener" href="https://saankhya.medium.com/mistral-instruct-7b-finetuning-on-medmcqa-dataset-6ec2532b1ff1">blog
by Saankhya Mondal</a>.</li>
</ol>
</div><script src="https://jsd.onmicrosoft.cn/npm/hexo-theme-a4@latest/source/js/lightgallery.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script>
    </div>

    <div class="post-meta">
        <i>
        
            <span>2023-12-25</span>
            
                <span>ËØ•ÁØáÊñáÁ´†Ë¢´ Zimo</span>
            
            
                <span>Êâì‰∏äÊ†áÁ≠æ:
                    
                    
                        <a href='/tags/LLM/'>
                            LLM
                        </a>
                    
                        <a href='/tags/clinic/'>
                            clinic
                        </a>
                    
                </span>
             
             
        
        </i>
    </div>
    <br>
    
    <!-- <div class="post-footer-pre-next">
        <span>‰∏ä‰∏ÄÁØáÔºö<a href=""></a></span>
        <span class="post-footer-pre-next-last-span-right">‰∏ä‰∏ÄÁØáÔºö<a href=""></a></span>
    </div> -->

    
        

     
</div>



                                      
                    
                    
                    <div class="footer">
    
        <span> 
            ¬© 1949-2024 China 

            
                

            
        </span>
    
</div>
<!--ËøôÊòØÊåá‰∏ÄÊù°Á∫øÂæÄ‰∏ãÁöÑÂÜÖÂÆπ-->
<div class="footer-last">
    
            <span>Èïø‰∫≠Â§ñÔºåÂè§ÈÅìËæπÔºåËä≥ËçâÁ¢ßËøûÂ§©</span>
            
    
</div>


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>

    <!--ÁõÆÂΩï-->
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tocify/1.9.0/javascripts/jquery.tocify.min.js" type="text/javascript" ></script>
        
<script src="/js/toc.js"></script>

    

    
<script src="/js/randomHeaderContent.js"></script>

    <!--ÂõûÂà∞È°∂ÈÉ®ÊåâÈíÆ-->
    
        
<script src="/js/returnToTop.js"></script>

    

    
        
<script src="/js/returnToLastPage.js"></script>

    





<script src="/js/lightgallery.min.js"></script>



                </div>
            
            
                <!-- ÂõûÂà∞È°∂ÈÉ®ÁöÑÊåâÈíÆ-->  
                <div class="progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
            
                <!-- ËøîÂõûÁöÑÊåâÈíÆ-->  
                <div class="return-to-last-progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
    </body>


    <!--ÊöóÈªëÊ®°Âºè-->
    <script src="/js/darkmode-js.min.js"></script>
    <script>
        function addDarkmodeWidget() {
        const options = {
            bottom: '53px', // default: '32px'
            right: 'unset', // default: '32px'
            left: '42px', // default: 'unset'
            time: '0.3s', // default: '0.3s'
            mixColor: '#fff', // default: '#fff'
            backgroundColor: ' #e8e0c9  ',  // default: '#fff'
            buttonColorDark: '#100f2c',  // default: '#100f2c'
            buttonColorLight: '#fff', // default: '#fff'
            saveInCookies: true, // default: true,
            label: 'üåì', // default: ''
            autoMatchOsTheme: true // default: true
        }
    
        const darkmode = new Darkmode(options);
        darkmode.showWidget();
        
        }
        window.addEventListener('load', addDarkmodeWidget);
    </script>
  
</html>